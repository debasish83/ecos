<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Spark Summit Talk, July 2014 powered by reveal.js</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Hakim El Hattab">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.min.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', include the PDF print sheet -->
		<script>
			if (window.location.search.match(/print-pdf/gi)) {
				var link = document.createElement('link');
				link.rel = 'stylesheet';
				link.type = 'text/css';
				link.href = 'css/print/pdf.css';
				document.getElementsByTagName( 'head' )[0].appendChild(link);
			}
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h2>Quadratic Programing Solver for Non-negative Matrix Factorization with Spark</h2>
					<p>
						<small> Debasish Das &nbsp;&nbsp; Santanu Das</small>
					</p>
				</section>

				<section>
					<h3>Roadmap</h3>
					<div align="left">
						<p>
							<ul>
								<li>
									Some overview on Matrix Factorization
								</li>
								<li>
									QP formulation of Non-negative Matrix Factorization (NMF)
								</li>
								<li>
									Algorithms to solve quadratic programming problems
								</li>
								<li>
									Some QP Use Cases (on public data)
								</li>
								<ul>
									<li>
										unconstrained
									</li>
									<li>
										linear constrained
									</li>
									<ul>
										<li>
											box constraints
										</li>
										<li>
											inquality constraint
										</li>
										<li>
											equality constraint
										</li>
									</ul>
								</ul>
								<li>
									Results &amp; Discussions
								</li>
								<ul>
									<li>
										Regularized Least Square
									</li>
									<li>
										Interior point method
									</li>
									<li>
										Alternating Direction Method of Multipliers
									</li>
									<li>
										Octave validation
									</li>
								</ul>
							</ul>
						</p>
					</div>
				</section>

				<section>
					<h3>Matrix Factorization</h3>
					<div align="left">
						<p>
							What it is- To decompose observed data (matrix):
							<ul>
								<li>
									Factors/component matrix
								</li>
								<li>
									Coefficient matrix
								</li>
							</ul>
						</p>

						<p>
							Goal- minimize reconstruction error
						</p>

						<p>
							Problem Formulation-
						</p>

					</div>

					<p>
						$R_{p \times n} = W_{p \times r}H_{r \times n} + E_{p \times n}$
					</p>

					<div align="left">
						To Solve for W &amp; H
					</div>

					<p>
						$D^{\alpha}(R || W,H)=\frac{1}{2}||R_{p \times n} - W_{p \times r}H_{r \times n}||^{2}_{F} + \\
						{\alpha}_{l1w}||W|| + {\alpha}_{l2w}||W||^{2}_{F} +  \lambda_{l1h}|H||| + \lambda_{l2h}||H||^{2}_{F}$
					</p>

					<div align="left">
						Further- Use case drives Usability and Interpretability
						<p>
							<ul>
								<li>
									Non-negativity
								</li>
								<li>
									Smoothness
								</li>
								<li>
									Sparsity
								</li>
							</ul>
						</p>
					</div>
				</section>

				<section>
					<h3> Regularized Alternating Least Square (RALS)</h3>

					<div align="left">
						<p>
							Gradient of the cost function wrt unknown matrices ($W$, $H$)
						</p>

					</div>
					<div align="left">
						<p>
							Fixed-point RALS Algorithm: Equating gradient to zero, we get the iterative update scheme of $W$, $H$
						</p>
						<ul>
							<li>
								start random / specific initialization of $W$
							</li>
							<li>
								estimate $H$, given $W$
							</li>
							<li>
								enforce positivity (NMF)
							</li>
							<li>
								REPEAT until convergence
							</li>
						</ul>
						<p>
							Regularization constants: Fixed or dynamically varied
						</p>
						<p>
							Other forms of update scheme: Multiplicative / Additive etc.
						</p>
					</div>
				</section>

				<section>
					<h3> Constraints: NMF vs Other MF</h3>

					<div align="left">
						<p>
							PCA constraints columns of W to be orthonormal and rows of H to be strictly orthogonal to each other.
						</p>
						<p>
							K-means constraints rows of H to be strictly orthogonal to each other. H represents indicator matrix (clusters) and W represent cluster centers.
						</p>
						<p>
							Non-negativity property of NMF allows additive combinations, no subtraction occurs.
							<ul>
								<li>
									Suitable for part-based representation and intuitive as the combined parts form the whole representation
								</li>
							</ul>
						</p>
						<p>
							Current effort aims to introduce flexibility to impose additional constraints (e.g. bounds on variables, sparsity, etc.)
						</p>

					</div>
				</section>

				<section>
					<h3> NMF - Essentially Clustering</h3>

					<div align="left">
						<p>
							$D(R || W,H)=\frac{1}{2}||R_{p \times n} - W_{p \times r}H_{r \times n}||^{2}_{F}$
						</p>
						<p>
							$=\frac{1}{2}\sum^{n}_{i=1}||r_{i}-Wh_{i}||^{2}_{2}$
						</p>
						<ul>
							<li>
								$W=[w_{1},w_{2},w_{3},…w_{r}]$ : cluster centers/factors
						</ul>
						<p>
							Solve   $n$ independent problems:
						</p>
						<ul>
							<li>
								$min_{h_{i}\ge 0} \frac{1}{2} ||r_{i}-Wh_{i}||^{2}_{2}$
							</li>
							<li>
								Aggregated solutions: $H=[h_{1},h_{2},h_{3},…h_{n}]$
							</li>
							<li>
								Intuition: $h_{ik}$ is the measure that $r_{i}$ belongs to cluster $k$ i.e. ideally if $r_{i}$  is the exact representative of cluster $r$ then $h_{ik}=1$
							</li>
						</ul>
						<p>
							Given $W$, we compute cluster possibilities ($H$) using a QP solver in Spark Mllib.
						</p>
					</div>
				</section>

				<section>
					<h3> QP to ADMM/SOCP </h3>
					<ul>
						<li>
							ADMM : what is it? When we use it?
						</li>
						<li>
							QP to SOCP is solved using Interior Point Method (ECOS)
						</li>
						<li>
							QP to ADMM is solved using Cholesky Factorization based Solver
						</li>
						<li>
							SOCP: what is it? When we use it?
						</li>
					</ul>
				</section>

				<section>
					<h3> QP: ADMM formulation </h3>
					<div align="left">
						<p>
							Objective
							$f(h): 0.5||r-Wh||^{2}_{2} => 0.5h^{T}(WW^{T})h - (r^{T}W)h$
						</p>
						<p>
							Constraints
							$g(z) : z >= 0$
						</p>
						<p>
							ADMM formulation
							$f(h) + g(z) \\
							\text{s.t } h = z$
						</p>

						<p>
							ADMM Steps
							<ul>
								<li>
									$h^{k+1} = argmin_{h} (f(h + 0.5 \times \rho ||h - z^{k} + u^{k}))$
								</li>
								<li>
									$z^{k+1} = x^{k+1} + u^{k} \text{s.t } z^{k+1} \in g(z)$
								</li>
								<li>
									$u^{k+1} = u^{k} + x_{k+1} - z_{k+1}$
								</li>
							</ul>
						</p>
					</div>
				</section>
</section>
				
				<section>
					<h3> QP: ADMM Implementation</h3>
					<pre><code>class DirectQpSolver(nGram: Int,
  lb: Option[DoubleMatrix] = None, ub: Option[DoubleMatrix] = None,
  Aeq: Option[DoubleMatrix] = None, 
  alpha: Double = 0.0, rho: Double = 0.0, 
  addEqualityToGram: Boolean = false) = {
 
def solve(q: DoubleMatrix, beq: Option[DoubleMatrix]): DoubleMatrix = {
    //Dense cholesky factorization
    val R = Decompose.cholesky(wsH)
    val Rtrans = R.transpose()
    
    while (k &le; ITERS) {
      	//scale = rho*(z - u) - q
      	scale.fill(0).addi(z).subi(u).muli(rho).subi(q)
      	
      	//Use Dpotrs solve if structure of Hessian supports it
      	
      	//Step 1 : scale * y = R'
      	val scaledR = Solve.solve(Rtrans, scale)

      	//Step 2 : y * x = R
      	val x = Solve.solve(R, scaledR)
      
      	//z-update with relaxation

      	//zold = (1-alpha)*z
      	//x_hat = alpha*x + zold
      	zOld.fill(0).addi(z).muli(1 - alpha)
      	xHat.fill(0).addi(x).muli(alpha).addi(zOld)
      	
      	//zold = z
      	zOld.fill(0).addi(z)
      	//z = xHat + u
      	z.fill(0).addi(xHat).addi(u)
      	//Apply proximal operators
      	Proximal(z)
      	if(converged(x, z, u)) return x
      	k = k + 1
    }
  }
}
</code></pre>																									
</section>

				<section>
					<h3> QP: SOCP formulation </h3>
					<div align="left">
						<p>
							Objective transformation
							$\text{minimize } t \\
							\text{ s.t } 0.5h^{T}(WW^{T})h - (r^{T}W)h \leq t$
						</p>
						<p>
							Constraints
							$h >= 0 \\
							Aeq \times h = Beq \\
							A \times h \leq B$
						</p>
						<p>
							Quadratic constraint transformation
						</p>
						$[{Q_{chol}h};{c}]_{2} \leq d$
					</div>
				</section>
				
				<section>
					<h3> QP: SOCP Implementation</h3>
					<pre><code>class QpSolver(nGram: Int, nLinear: Int = 0,diagonal: Boolean = false,
	Equalities: Option[CSCMatrix[Double]] = None, 
	Inequalities: Option[CSCMatrix[Double]] = None, 
	lbFlag: Boolean = false, ubFlag: Boolean = false) = {

	NativeECOS.loadLibraryAndCheckErrors()					
  							
	def solve(H: DoubleMatrix, f: Array[Double]): (Int, Array[Double]) = {
    				
		updateHessian(H)
    				
		updateLinearObjective(f)
    				
		val status = NativeECOS.solveSocp(c, G.rows, G.cols, 
											G.data, G.colPtrs, G.rowIndices, hBuilder,
											Aeq.rows, Aeq.cols, 
											Aeq.data, Aeq.colPtrs, Aeq.rowIndices, beqBuilder,
											linear, cones, x)			
		
		(status, x.slice(0, n))
	}
}
</code></pre>
</section>

				<section>
					<h2>Use Case: Positivity</h2>
					<pre><code>
						
					</code></pre>
					<p>comps</p>
					<p>application</p>
					
				</section>

				<section>
					<h2>Use Case: Sparsity</h2>
					<pre><code>
						
					</code></pre>
					<p>comps</p>
					<p>application</p>
				</section>

				<section>
					<h2>Use Case: Equality with bound</h2>
					<pre><code>
											
					</code></pre>
					<p>comps</p>
					<p>application</p>

				</section>

				<section>
					<h2>RunTime</h2>
				</section>

				<section>
					<h2>Future work</h2>
				</section>

				<section>
					<h2>Questions</h2>
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>
			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls : true,
				progress : true,
				history : true,
				center : true,

				theme : Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition : Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Parallax scrolling
				// parallaxBackgroundImage: 'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg',
				// parallaxBackgroundSize: '2100px 900px',
				math : {
					mathjax : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js',
					config : 'TeX-AMS_HTML-full' // See http://docs.mathjax.org/en/latest/config-files.html
				},

				// Optional libraries used to extend on reveal.js
				dependencies : [{
					src : 'lib/js/classList.js',
					condition : function() {
						return !document.body.classList;
					}
				}, {
					src : 'plugin/markdown/marked.js',
					condition : function() {
						return !!document.querySelector('[data-markdown]');
					}
				}, {
					src : 'plugin/markdown/markdown.js',
					condition : function() {
						return !!document.querySelector('[data-markdown]');
					}
				}, {
					src : 'plugin/highlight/highlight.js',
					async : true,
					callback : function() {
						hljs.initHighlightingOnLoad();
					}
				}, {
					src : 'plugin/zoom-js/zoom.js',
					async : true,
					condition : function() {
						return !!document.body.classList;
					}
				}, {
					src : 'plugin/notes/notes.js',
					async : true,
					condition : function() {
						return !!document.body.classList;
					}
				}, {
					src : 'plugin/math/math.js',
					async : true
				}]
			});

		</script>

	</body>
</html>
